"""
Monitoring and analytics system for multi-agent collaboration in Xencode
"""
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import uuid
import json
import sqlite3
import threading
import time
from collections import defaultdict, deque
import statistics


class MetricType(Enum):
    """Types of metrics tracked in the system."""
    AGENT_UTILIZATION = "agent_utilization"
    TASK_COMPLETION_RATE = "task_completion_rate"
    RESPONSE_TIME = "response_time"
    COLLABORATION_EFFICIENCY = "collaboration_efficiency"
    RESOURCE_USAGE = "resource_usage"
    COMMUNICATION_LATENCY = "communication_latency"
    TEAM_FORMATION_SUCCESS = "team_formation_success"
    LEARNING_EFFICIENCY = "learning_efficiency"


class AlertSeverity(Enum):
    """Severity levels for alerts."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class Metric:
    """Represents a single metric measurement."""
    metric_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    metric_type: MetricType = MetricType.AGENT_UTILIZATION
    agent_id: Optional[str] = None
    team_id: Optional[str] = None
    value: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    source: str = ""  # Which component generated the metric


@dataclass
class Alert:
    """Represents an alert generated by the monitoring system."""
    alert_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    severity: AlertSeverity = AlertSeverity.INFO
    title: str = ""
    description: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    metric_id: Optional[str] = None
    agent_id: Optional[str] = None
    resolved: bool = False
    resolved_at: Optional[datetime] = None


@dataclass
class CollaborationStats:
    """Aggregated statistics for collaboration."""
    period_start: datetime = field(default_factory=datetime.now)
    period_end: datetime = field(default_factory=datetime.now)
    total_tasks: int = 0
    successful_tasks: int = 0
    failed_tasks: int = 0
    avg_response_time: float = 0.0
    avg_collaboration_efficiency: float = 0.0
    total_agents_active: int = 0
    avg_agent_utilization: float = 0.0
    communication_events: int = 0
    resource_allocations: int = 0
    team_formations: int = 0
    avg_team_size: float = 0.0


class MetricsCollector:
    """Collects metrics from various sources in the multi-agent system."""
    
    def __init__(self, db_path: str = "metrics.db"):
        self.db_path = db_path
        self.metrics_buffer: List[Metric] = []
        self.alerts_buffer: List[Alert] = []
        self.access_lock = threading.RLock()
        self.metric_thresholds: Dict[MetricType, Tuple[float, float]] = {}  # (warning, critical)
        
        # Initialize database
        self._init_db()
        
        # Set default thresholds
        self._set_default_thresholds()
    
    def _init_db(self):
        """Initialize the metrics database."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Create metrics table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                metric_id TEXT PRIMARY KEY,
                metric_type TEXT,
                agent_id TEXT,
                team_id TEXT,
                value REAL,
                timestamp TEXT,
                metadata TEXT,
                source TEXT
            )
        ''')
        
        # Create alerts table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                alert_id TEXT PRIMARY KEY,
                severity TEXT,
                title TEXT,
                description TEXT,
                timestamp TEXT,
                metric_id TEXT,
                agent_id TEXT,
                resolved BOOLEAN,
                resolved_at TEXT
            )
        ''')
        
        # Create indexes
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metric_type ON metrics(metric_type)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_agent_metrics ON metrics(agent_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_team_metrics ON metrics(team_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_metric_timestamp ON metrics(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_alert_severity ON alerts(severity)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_alert_resolved ON alerts(resolved)')
        
        conn.commit()
        conn.close()
    
    def _set_default_thresholds(self):
        """Set default thresholds for metrics."""
        self.metric_thresholds = {
            MetricType.AGENT_UTILIZATION: (0.8, 0.95),  # Warning at 80%, Critical at 95%
            MetricType.TASK_COMPLETION_RATE: (0.7, 0.5),  # Warning at 70%, Critical at 50%
            MetricType.RESPONSE_TIME: (5.0, 10.0),  # Warning at 5s, Critical at 10s
            MetricType.COLLABORATION_EFFICIENCY: (0.6, 0.4),  # Warning at 60%, Critical at 40%
            MetricType.RESOURCE_USAGE: (0.85, 0.95),  # Warning at 85%, Critical at 95%
            MetricType.COMMUNICATION_LATENCY: (0.5, 1.0),  # Warning at 0.5s, Critical at 1s
            MetricType.TEAM_FORMATION_SUCCESS: (0.7, 0.5),  # Warning at 70%, Critical at 50%
            MetricType.LEARNING_EFFICIENCY: (0.5, 0.3)  # Warning at 50%, Critical at 30%
        }
    
    def record_metric(self, metric: Metric) -> Optional[Alert]:
        """Record a metric and potentially generate an alert."""
        with self.access_lock:
            # Store in database
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO metrics 
                (metric_id, metric_type, agent_id, team_id, value, timestamp, metadata, source)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                metric.metric_id,
                metric.metric_type.value,
                metric.agent_id,
                metric.team_id,
                metric.value,
                metric.timestamp.isoformat(),
                json.dumps(metric.metadata),
                metric.source
            ))
            
            conn.commit()
            conn.close()
            
            # Check if this metric triggers an alert
            alert = self._check_metric_threshold(metric)
            if alert:
                self._store_alert(alert)
            
            return alert
    
    def _check_metric_threshold(self, metric: Metric) -> Optional[Alert]:
        """Check if a metric exceeds its threshold and create an alert if needed."""
        if metric.metric_type not in self.metric_thresholds:
            return None
        
        warning_thresh, critical_thresh = self.metric_thresholds[metric.metric_type]
        
        # Determine severity based on thresholds
        severity = None
        title = ""
        description = ""
        
        if metric.metric_type in [MetricType.AGENT_UTILIZATION, MetricType.RESOURCE_USAGE, 
                                  MetricType.RESPONSE_TIME, MetricType.COMMUNICATION_LATENCY]:
            # Higher values are worse for these metrics
            if metric.value >= critical_thresh:
                severity = AlertSeverity.CRITICAL
                title = f"Critical {metric.metric_type.value} threshold exceeded"
                description = f"Value {metric.value} exceeds critical threshold {critical_thresh}"
            elif metric.value >= warning_thresh:
                severity = AlertSeverity.WARNING
                title = f"Warning {metric.metric_type.value} threshold exceeded"
                description = f"Value {metric.value} exceeds warning threshold {warning_thresh}"
        else:
            # Lower values are worse for these metrics (completion rates, efficiency, etc.)
            if metric.value <= critical_thresh:
                severity = AlertSeverity.CRITICAL
                title = f"Critical {metric.metric_type.value} threshold exceeded"
                description = f"Value {metric.value} falls below critical threshold {critical_thresh}"
            elif metric.value <= warning_thresh:
                severity = AlertSeverity.WARNING
                title = f"Warning {metric.metric_type.value} threshold exceeded"
                description = f"Value {metric.value} falls below warning threshold {warning_thresh}"
        
        if severity:
            return Alert(
                severity=severity,
                title=title,
                description=description,
                metric_id=metric.metric_id,
                agent_id=metric.agent_id
            )
        
        return None
    
    def _store_alert(self, alert: Alert):
        """Store an alert in the database."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO alerts
            (alert_id, severity, title, description, timestamp, metric_id, agent_id, resolved, resolved_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            alert.alert_id,
            alert.severity.value,
            alert.title,
            alert.description,
            alert.timestamp.isoformat(),
            alert.metric_id,
            alert.agent_id,
            alert.resolved,
            alert.resolved_at.isoformat() if alert.resolved_at else None
        ))
        
        conn.commit()
        conn.close()
    
    def get_metrics_by_type(self, metric_type: MetricType, start_time: datetime, 
                           end_time: datetime, agent_id: Optional[str] = None) -> List[Metric]:
        """Get metrics of a specific type within a time range."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        query = '''
            SELECT * FROM metrics 
            WHERE metric_type = ? AND timestamp BETWEEN ? AND ?
        '''
        params = [metric_type.value, start_time.isoformat(), end_time.isoformat()]
        
        if agent_id:
            query += " AND agent_id = ?"
            params.append(agent_id)
        
        query += " ORDER BY timestamp DESC"
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        metrics = []
        for row in rows:
            metric = Metric(
                metric_id=row[0],
                metric_type=MetricType(row[1]),
                agent_id=row[2],
                team_id=row[3],
                value=row[4],
                timestamp=datetime.fromisoformat(row[5]),
                metadata=json.loads(row[6]) if row[6] else {},
                source=row[7]
            )
            metrics.append(metric)
        
        return metrics
    
    def get_recent_alerts(self, limit: int = 50, severity: Optional[AlertSeverity] = None, 
                         resolved: Optional[bool] = None) -> List[Alert]:
        """Get recent alerts with optional filters."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        query = "SELECT * FROM alerts WHERE 1=1"
        params = []
        
        if severity:
            query += " AND severity = ?"
            params.append(severity.value)
        
        if resolved is not None:
            query += " AND resolved = ?"
            params.append(resolved)
        
        query += " ORDER BY timestamp DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        alerts = []
        for row in rows:
            alert = Alert(
                alert_id=row[0],
                severity=AlertSeverity(row[1]),
                title=row[2],
                description=row[3],
                timestamp=datetime.fromisoformat(row[4]),
                metric_id=row[5],
                agent_id=row[6],
                resolved=bool(row[7]),
                resolved_at=datetime.fromisoformat(row[8]) if row[8] else None
            )
            alerts.append(alert)
        
        return alerts
    
    def resolve_alert(self, alert_id: str):
        """Mark an alert as resolved."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE alerts 
            SET resolved = ?, resolved_at = ? 
            WHERE alert_id = ?
        ''', (True, datetime.now().isoformat(), alert_id))
        
        conn.commit()
        conn.close()


class CollaborationAnalyzer:
    """Analyzes collaboration patterns and generates insights."""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.access_lock = threading.RLock()
    
    def generate_collaboration_stats(self, start_time: datetime, end_time: datetime) -> CollaborationStats:
        """Generate aggregated collaboration statistics for a time period."""
        with self.access_lock:
            # Get all metrics for the period
            all_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.TASK_COMPLETION_RATE, start_time, end_time
            )
            
            # Count successful and failed tasks
            successful_tasks = sum(1 for m in all_metrics if m.value >= 0.8)  # Assuming 0.8+ is success
            failed_tasks = sum(1 for m in all_metrics if m.value < 0.8)
            
            # Get response times
            response_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.RESPONSE_TIME, start_time, end_time
            )
            avg_response_time = statistics.mean([m.value for m in response_metrics]) if response_metrics else 0.0
            
            # Get collaboration efficiency
            efficiency_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.COLLABORATION_EFFICIENCY, start_time, end_time
            )
            avg_efficiency = statistics.mean([m.value for m in efficiency_metrics]) if efficiency_metrics else 0.0
            
            # Get agent utilization
            utilization_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.AGENT_UTILIZATION, start_time, end_time
            )
            avg_utilization = statistics.mean([m.value for m in utilization_metrics]) if utilization_metrics else 0.0
            
            # Get unique agents active
            active_agents = set(m.agent_id for m in all_metrics if m.agent_id)
            
            # Get communication events
            comm_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.COMMUNICATION_LATENCY, start_time, end_time
            )
            
            # Get resource allocations
            resource_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.RESOURCE_USAGE, start_time, end_time
            )
            
            # Get team formations
            team_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.TEAM_FORMATION_SUCCESS, start_time, end_time
            )
            
            # Calculate average team size (simplified)
            avg_team_size = 3.0 if team_metrics else 0.0  # Placeholder
            
            return CollaborationStats(
                period_start=start_time,
                period_end=end_time,
                total_tasks=len(all_metrics),
                successful_tasks=successful_tasks,
                failed_tasks=failed_tasks,
                avg_response_time=avg_response_time,
                avg_collaboration_efficiency=avg_efficiency,
                total_agents_active=len(active_agents),
                avg_agent_utilization=avg_utilization,
                communication_events=len(comm_metrics),
                resource_allocations=len(resource_metrics),
                team_formations=len(team_metrics),
                avg_team_size=avg_team_size
            )
    
    def get_agent_performance(self, agent_id: str, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Get performance metrics for a specific agent."""
        with self.access_lock:
            # Get all metrics for the agent
            utilization_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.AGENT_UTILIZATION, start_time, end_time, agent_id
            )
            
            response_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.RESPONSE_TIME, start_time, end_time, agent_id
            )
            
            efficiency_metrics = self.metrics_collector.get_metrics_by_type(
                MetricType.COLLABORATION_EFFICIENCY, start_time, end_time, agent_id
            )
            
            # Calculate averages
            avg_utilization = statistics.mean([m.value for m in utilization_metrics]) if utilization_metrics else 0.0
            avg_response_time = statistics.mean([m.value for m in response_metrics]) if response_metrics else 0.0
            avg_efficiency = statistics.mean([m.value for m in efficiency_metrics]) if efficiency_metrics else 0.0
            
            # Get alert count for this agent
            all_alerts = self.metrics_collector.get_recent_alerts(limit=1000)
            agent_alerts = [a for a in all_alerts if a.agent_id == agent_id and start_time <= a.timestamp <= end_time]
            
            return {
                'agent_id': agent_id,
                'period_start': start_time,
                'period_end': end_time,
                'avg_utilization': avg_utilization,
                'avg_response_time': avg_response_time,
                'avg_efficiency': avg_efficiency,
                'total_metrics': len(utilization_metrics) + len(response_metrics) + len(efficiency_metrics),
                'alert_count': len(agent_alerts),
                'last_seen': max((m.timestamp for m in utilization_metrics), default=None)
            }
    
    def get_trend_analysis(self, metric_type: MetricType, start_time: datetime, 
                          end_time: datetime, interval_hours: int = 1) -> List[Dict[str, Any]]:
        """Get trend analysis for a specific metric type."""
        with self.access_lock:
            # Divide the time period into intervals
            current_time = start_time
            trends = []
            
            while current_time < end_time:
                interval_end = min(current_time + timedelta(hours=interval_hours), end_time)
                
                metrics = self.metrics_collector.get_metrics_by_type(
                    metric_type, current_time, interval_end
                )
                
                if metrics:
                    values = [m.value for m in metrics]
                    trend_point = {
                        'start_time': current_time,
                        'end_time': interval_end,
                        'count': len(values),
                        'avg_value': statistics.mean(values),
                        'min_value': min(values),
                        'max_value': max(values),
                        'std_dev': statistics.stdev(values) if len(values) > 1 else 0.0
                    }
                    trends.append(trend_point)
                
                current_time = interval_end
            
            return trends


class RealTimeDashboard:
    """Real-time dashboard for monitoring multi-agent collaboration."""
    
    def __init__(self, metrics_collector: MetricsCollector, collaboration_analyzer: CollaborationAnalyzer):
        self.metrics_collector = metrics_collector
        self.collaboration_analyzer = collaboration_analyzer
        self.access_lock = threading.RLock()
        self.dashboard_refresh_interval = 5  # seconds
        self.is_running = False
        self.dashboard_data = {}
    
    def start_monitoring(self):
        """Start the real-time monitoring loop."""
        if not self.is_running:
            self.is_running = True
            # In a real implementation, this would start a background thread
            # For now, we'll just update the data when requested
    
    def stop_monitoring(self):
        """Stop the real-time monitoring."""
        self.is_running = False
    
    def get_current_dashboard_data(self) -> Dict[str, Any]:
        """Get current dashboard data."""
        with self.access_lock:
            now = datetime.now()
            start_time = now - timedelta(minutes=15)  # Last 15 minutes
            
            # Get collaboration stats
            stats = self.collaboration_analyzer.generate_collaboration_stats(start_time, now)
            
            # Get recent alerts
            recent_alerts = self.metrics_collector.get_recent_alerts(limit=10)
            
            # Get agent performance
            # For this example, we'll simulate getting active agent IDs
            # In a real system, we'd get this from the active agents list
            sample_agents = [f"agent_{i}" for i in range(5)]  # Sample agent IDs
            agent_performance = []
            for agent_id in sample_agents:
                perf = self.collaboration_analyzer.get_agent_performance(agent_id, start_time, now)
                agent_performance.append(perf)
            
            # Get trend data for key metrics
            response_trends = self.collaboration_analyzer.get_trend_analysis(
                MetricType.RESPONSE_TIME, start_time, now, interval_hours=1
            )
            
            efficiency_trends = self.collaboration_analyzer.get_trend_analysis(
                MetricType.COLLABORATION_EFFICIENCY, start_time, now, interval_hours=1
            )
            
            self.dashboard_data = {
                'timestamp': now,
                'collaboration_stats': stats,
                'recent_alerts': recent_alerts,
                'agent_performance': agent_performance,
                'response_time_trends': response_trends,
                'efficiency_trends': efficiency_trends,
                'system_health': self._calculate_system_health(recent_alerts, stats)
            }
            
            return self.dashboard_data
    
    def _calculate_system_health(self, alerts: List[Alert], stats: CollaborationStats) -> str:
        """Calculate overall system health based on alerts and stats."""
        critical_alerts = [a for a in alerts if a.severity == AlertSeverity.CRITICAL]
        error_alerts = [a for a in alerts if a.severity == AlertSeverity.ERROR]
        warning_alerts = [a for a in alerts if a.severity == AlertSeverity.WARNING]
        
        if critical_alerts:
            return "CRITICAL"
        elif error_alerts:
            return "ERROR"
        elif warning_alerts:
            return "WARNING"
        elif stats.avg_collaboration_efficiency < 0.5:
            return "POOR"
        elif stats.avg_collaboration_efficiency < 0.7:
            return "FAIR"
        else:
            return "GOOD"


class MonitoringAnalyticsEngine:
    """Main engine for monitoring and analytics of multi-agent collaboration."""
    
    def __init__(self, metrics_db_path: str = "metrics.db"):
        self.metrics_collector = MetricsCollector(metrics_db_path)
        self.collaboration_analyzer = CollaborationAnalyzer(self.metrics_collector)
        self.real_time_dashboard = RealTimeDashboard(
            self.metrics_collector, 
            self.collaboration_analyzer
        )
        self.access_lock = threading.RLock()
    
    def record_agent_utilization(self, agent_id: str, utilization: float, metadata: Dict[str, Any] = None):
        """Record agent utilization metric."""
        metadata = metadata or {}
        metric = Metric(
            metric_type=MetricType.AGENT_UTILIZATION,
            agent_id=agent_id,
            value=utilization,
            metadata=metadata,
            source="agent_monitor"
        )
        return self.metrics_collector.record_metric(metric)
    
    def record_task_completion_rate(self, agent_id: str, completion_rate: float, 
                                   task_details: Dict[str, Any] = None):
        """Record task completion rate metric."""
        task_details = task_details or {}
        metric = Metric(
            metric_type=MetricType.TASK_COMPLETION_RATE,
            agent_id=agent_id,
            value=completion_rate,
            metadata=task_details,
            source="task_manager"
        )
        return self.metrics_collector.record_metric(metric)
    
    def record_response_time(self, agent_id: str, response_time: float, 
                           request_details: Dict[str, Any] = None):
        """Record response time metric."""
        request_details = request_details or {}
        metric = Metric(
            metric_type=MetricType.RESPONSE_TIME,
            agent_id=agent_id,
            value=response_time,
            metadata=request_details,
            source="communication_layer"
        )
        return self.metrics_collector.record_metric(metric)
    
    def record_collaboration_efficiency(self, team_id: str, efficiency: float, 
                                      collaboration_details: Dict[str, Any] = None):
        """Record collaboration efficiency metric."""
        collaboration_details = collaboration_details or {}
        metric = Metric(
            metric_type=MetricType.COLLABORATION_EFFICIENCY,
            team_id=team_id,
            value=efficiency,
            metadata=collaboration_details,
            source="team_coordinator"
        )
        return self.metrics_collector.record_metric(metric)
    
    def record_resource_usage(self, agent_id: str, usage_percentage: float, 
                            resource_details: Dict[str, Any] = None):
        """Record resource usage metric."""
        resource_details = resource_details or {}
        metric = Metric(
            metric_type=MetricType.RESOURCE_USAGE,
            agent_id=agent_id,
            value=usage_percentage,
            metadata=resource_details,
            source="resource_manager"
        )
        return self.metrics_collector.record_metric(metric)
    
    def get_collaboration_insights(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Get comprehensive collaboration insights for a time period."""
        with self.access_lock:
            stats = self.collaboration_analyzer.generate_collaboration_stats(start_time, end_time)
            
            # Get top performing agents
            sample_agents = [f"agent_{i}" for i in range(5)]
            agent_performances = []
            for agent_id in sample_agents:
                perf = self.collaboration_analyzer.get_agent_performance(agent_id, start_time, end_time)
                agent_performances.append(perf)
            
            # Sort by efficiency
            agent_performances.sort(key=lambda x: x['avg_efficiency'], reverse=True)
            
            # Get trend analysis
            efficiency_trends = self.collaboration_analyzer.get_trend_analysis(
                MetricType.COLLABORATION_EFFICIENCY, start_time, end_time
            )
            
            # Get recent alerts
            recent_alerts = self.metrics_collector.get_recent_alerts(limit=20)
            
            return {
                'collaboration_stats': stats,
                'top_performing_agents': agent_performances[:3],
                'efficiency_trends': efficiency_trends,
                'recent_alerts': recent_alerts,
                'insights_summary': self._generate_insights_summary(stats, recent_alerts)
            }
    
    def _generate_insights_summary(self, stats: CollaborationStats, alerts: List[Alert]) -> List[str]:
        """Generate a summary of insights from the data."""
        insights = []
        
        if stats.total_tasks > 0:
            success_rate = stats.successful_tasks / stats.total_tasks
            if success_rate < 0.8:
                insights.append(f"Task success rate is low at {success_rate:.2%}")
            else:
                insights.append(f"Good task success rate of {success_rate:.2%}")
        
        if stats.avg_response_time > 5.0:
            insights.append(f"Average response time is high at {stats.avg_response_time:.2f}s")
        
        if stats.avg_collaboration_efficiency < 0.6:
            insights.append(f"Collaboration efficiency could be improved at {stats.avg_collaboration_efficiency:.2f}")
        
        critical_alerts = [a for a in alerts if a.severity in [AlertSeverity.CRITICAL, AlertSeverity.ERROR]]
        if critical_alerts:
            insights.append(f"Attention needed: {len(critical_alerts)} critical/error alerts in the period")
        
        return insights


# Helper functions for common monitoring operations
def create_utilization_metric(agent_id: str, utilization: float) -> Metric:
    """Create a utilization metric."""
    return Metric(
        metric_type=MetricType.AGENT_UTILIZATION,
        agent_id=agent_id,
        value=utilization,
        source="auto_monitor"
    )


def create_efficiency_metric(team_id: str, efficiency: float) -> Metric:
    """Create a collaboration efficiency metric."""
    return Metric(
        metric_type=MetricType.COLLABORATION_EFFICIENCY,
        team_id=team_id,
        value=efficiency,
        source="team_analyzer"
    )